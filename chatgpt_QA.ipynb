{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge6z8v1-9a3c"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.callbacks.streaming_stdout_final_only import (\n",
        "    FinalStreamingStdOutCallbackHandler,\n",
        ")\n",
        "from langchain.agents import AgentType\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import pinecone\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = \"\"\n",
        "pinecone_key = os.getenv(\"PINECONE_KEY\")\n",
        "pinecone_env = os.getenv(\"PINECONE_ENV\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5QJtJ5Z9a3e"
      },
      "outputs": [],
      "source": [
        "pinecone.init(api_key=pinecone_key, environment=pinecone_env)\n",
        "index = pinecone.Index('chagpt_text_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M_OzTMf9a3f"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "vectordb = Pinecone(index, embedding_function=embeddings.embed_query, text_key=\"text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwinDIrv9a3f"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.callbacks.streaming_stdout_final_only import (\n",
        "    FinalStreamingStdOutCallbackHandler,\n",
        ")\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    temperature=0,\n",
        "    model_name = \"gpt-3.5-turbo-16k\",\n",
        "    streaming=True,\n",
        "    callbacks=[FinalStreamingStdOutCallbackHandler()],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4exua4-9a3g"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "retriever = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectordb.as_retriever(),\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDVUSmHE9a3h"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "tool_desc = \"\"\"Tool Description\"\"\"\n",
        "tools = [Tool(\n",
        "    func=retriever.run,\n",
        "    description=tool_desc,\n",
        "    name='tool name'\n",
        ")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-GY3n1m9a3h"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import DynamoDBChatMessageHistory\n",
        "\n",
        "chat_history = DynamoDBChatMessageHistory(table_name='conversation-store', session_id='qasc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRZDbl6k9a3h"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")\n",
        "memory.chat_memory = chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mflWaeN79a3h"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "conversational_agent = initialize_agent(\n",
        "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mirLInKy9a3i"
      },
      "outputs": [],
      "source": [
        "sys_pro = \"\"\"system_message Description\n",
        "\"\"\"\n",
        "prompt = conversational_agent.agent.create_prompt(\n",
        "    system_message=sys_pro,\n",
        "    tools=tools\n",
        ")\n",
        "conversational_agent.agent.llm_chain.prompt = prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1nPV8k_9a3i"
      },
      "outputs": [],
      "source": [
        "memory.chat_memory.messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLkzOpWV9a3i"
      },
      "outputs": [],
      "source": [
        "hello = conversational_agent.run(\"Hello\")\n",
        "print(hello)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1QTQKLu9a3j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "openai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}